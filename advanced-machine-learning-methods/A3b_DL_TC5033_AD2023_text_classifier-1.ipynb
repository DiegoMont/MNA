{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940c6dbc",
   "metadata": {},
   "source": [
    "## TC 5033\n",
    "### Word Embeddings\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Activity 3b: Text Classification using RNNs and AG_NEWS dataset in PyTorch\n",
    "<br>\n",
    "\n",
    "- Objective:\n",
    "    - Understand the basics of Recurrent Neural Networks (RNNs) and their application in text classification.\n",
    "    - Learn how to handle a real-world text dataset, AG_NEWS, in PyTorch.\n",
    "    - Gain hands-on experience in defining, training, and evaluating a text classification model in PyTorch.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Instructions:\n",
    "    - Data Preparation: Starter code will be provided that loads the AG_NEWS dataset and prepares it for training. Do not modify this part. However, you should be sure to understand it, and comment it, the use of markdown cells is suggested. \n",
    "\n",
    "    - Model Setup: A skeleton code for the RNN model class will be provided. Complete this class and use it to instantiate your model.\n",
    "\n",
    "    - Implementing Accuracy Function: Write a function that takes model predictions and ground truth labels as input and returns the model's accuracy.\n",
    "\n",
    "    - Training Function: Implement a function that performs training on the given model using the AG_NEWS dataset. Your model should achieve an accuracy of at least 80% to get full marks for this part.\n",
    "\n",
    "    - Text Sampling: Write a function that takes a sample text as input and classifies it using your trained model.\n",
    "\n",
    "    - Confusion Matrix: Implement a function to display the confusion matrix for your model on the test data.\n",
    "\n",
    "    - Submission: Submit your completed Jupyter Notebook. Make sure to include a markdown cell at the beginning of the notebook that lists the names of all team members. Teams should consist of 3 to 4 members.\n",
    "    \n",
    "<br>\n",
    "\n",
    "- Evaluation Criteria:\n",
    "\n",
    "    - Correct setup of all the required libraries and modules (10%)\n",
    "    - Code Quality (30%): Your code should be well-organized, clearly commented, and easy to follow. Use also markdown cells for clarity. Comments should be given for all the provided code, this will help you understand its functionality.\n",
    "    \n",
    "   - Functionality (60%): \n",
    "        - All the functions should execute without errors and provide the expected outputs.\n",
    "        - RNN model class (20%)\n",
    "        - Accuracy fucntion (10%)\n",
    "        - Training function (10%)\n",
    "        - Sampling function (10%)\n",
    "        - Confucion matrix (10%)\n",
    "\n",
    "        - The model should achieve at least an 80% accuracy on the AG_NEWS test set for full marks in this criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de318da",
   "metadata": {},
   "source": [
    "Dataset\n",
    "\n",
    "https://pytorch.org/text/stable/datasets.html#text-classification\n",
    "\n",
    "https://paperswithcode.com/dataset/ag-news\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9801f9",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bab55f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "\n",
    "\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38956d",
   "metadata": {},
   "source": [
    "### Get the train and the test datasets and dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6b784",
   "metadata": {},
   "source": [
    "Classes:\n",
    "\n",
    "* 1 - World\n",
    "\n",
    "* 2 - Sports\n",
    "\n",
    "* 3 - Business\n",
    "\n",
    "* 4 - Sci/Tech\n",
    "\n",
    "We will convert them to:\n",
    "\n",
    "* 0 - World\n",
    "\n",
    "* 1 - Sports\n",
    "\n",
    "* 2 - Business\n",
    "\n",
    "* 3 - Sci/Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49fbed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/nlp/lib/python3.10/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import functional\n",
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "\n",
    "DATA_PATH = \"data\"\n",
    "train_dataset = AG_NEWS(root=DATA_PATH, split=\"train\")\n",
    "train_dataset = functional.to_map_style_dataset(train_dataset)\n",
    "test_dataset = AG_NEWS(root=DATA_PATH, split=\"test\")\n",
    "test_dataset = functional.to_map_style_dataset(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c372eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import utils\n",
    "\n",
    "\n",
    "# Get the tokeniser\n",
    "# tokeniser object\n",
    "tokeniser = utils.get_tokenizer('basic_english')\n",
    "\n",
    "def yield_tokens(data):\n",
    "    for _, text in data:\n",
    "        yield tokeniser(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "794d0375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab\n",
    "\n",
    "\n",
    "# Build the vocabulary\n",
    "vocabulary = vocab.build_vocab_from_iterator(yield_tokens(train_dataset), specials=[\"<unk>\"])\n",
    "#set unknown token at position 0\n",
    "vocabulary.set_default_index(vocabulary[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b48268d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['welcome', 'to', 'te3007'] [3314, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "#test tokens\n",
    "tokens = tokeniser('Welcome to TE3007')\n",
    "print(tokens, vocabulary(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8c8f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN = int(len(train_dataset)*0.9)\n",
    "NUM_VAL = len(train_dataset) - NUM_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8290895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset\n",
    "\n",
    "\n",
    "train_dataset, val_dataset = dataset.random_split(train_dataset, [NUM_TRAIN, NUM_VAL])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc75b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108000 12000 120000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85563784",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "max_tokens = 50\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffdbf077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function passed to the DataLoader to process a batch of data as indicated\n",
    "def collate_batch(batch):\n",
    "    # Get label and text\n",
    "    y, x = list(zip(*batch))\n",
    "    \n",
    "    # Create list with indices from tokeniser\n",
    "    x = [vocabulary(tokeniser(text)) for text in x]\n",
    "    x = [t + ([0]*(max_tokens - len(t))) if len(t) < max_tokens else t[:max_tokens] for t in x]\n",
    "\n",
    "    # Prepare the labels, by subtracting 1 to get them in the range 0-3\n",
    "    return torch.tensor(x, dtype=torch.int32), torch.tensor(y, dtype=torch.long) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a55e6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b98898",
   "metadata": {},
   "source": [
    "### Let us build our RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50f20793",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50  # complete\n",
    "NEURONS = 64  # complete\n",
    "LAYERS = 3  # complete\n",
    "NUM_CLASSES = len(labels)  # complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f7f5621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Embedding, Linear, GRU\n",
    "\n",
    "\n",
    "class RNN_Model_1(Module):\n",
    "    def __init__(self, embed_size, hidden, layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = Embedding(num_embeddings=len(vocabulary), embedding_dim=embed_size)\n",
    "        self.rnn = GRU(embed_size, hidden, num_layers=layers, batch_first=True)\n",
    "        self.fc = Linear(hidden, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        out, hidden = self.rnn(x)\n",
    "        out = hidden[-1, :, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a42613f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, Module\n",
    "\n",
    "\n",
    "def accuracy(model: Module, loader: DataLoader):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    data_loss = 0\n",
    "    true_positives = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            texts, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            data_loss += loss.item()\n",
    "            predictions = torch.max(outputs, 1).indices\n",
    "            true_positives += torch.eq(predictions, labels).int().sum().cpu().item()\n",
    "    data_loss /= len(loader)\n",
    "    acc = true_positives / len(loader.dataset)\n",
    "    return acc, data_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e843e1f",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(model: Module, optimizer, epochs: int):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            texts, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "        acc, val_loss = accuracy(model, val_loader)\n",
    "        print(f\"Epoch {epoch+1} - loss: {round(train_loss, 4)} - val_loss: {round(val_loss, 4)} - accuracy: {round(acc, 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87775b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "\n",
    "\n",
    "epochs = 8  # define\n",
    "lr = 0.001  # to do\n",
    "# instantiate model\n",
    "rnn_model = RNN_Model_1(EMBEDDING_SIZE, NEURONS, LAYERS, NUM_CLASSES).to(device)\n",
    "optimiser = Adam(rnn_model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aec12a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.8183 - val_loss: 0.4642 - accuracy: 0.8309\n",
      "Epoch 2 - loss: 0.3765 - val_loss: 0.355 - accuracy: 0.8749\n",
      "Epoch 3 - loss: 0.2848 - val_loss: 0.3157 - accuracy: 0.8892\n",
      "Epoch 4 - loss: 0.2339 - val_loss: 0.2996 - accuracy: 0.8969\n",
      "Epoch 5 - loss: 0.1937 - val_loss: 0.2947 - accuracy: 0.9011\n",
      "Epoch 6 - loss: 0.1621 - val_loss: 0.3002 - accuracy: 0.9021\n",
      "Epoch 7 - loss: 0.1365 - val_loss: 0.3046 - accuracy: 0.9025\n",
      "Epoch 8 - loss: 0.1143 - val_loss: 0.3233 - accuracy: 0.9022\n"
     ]
    }
   ],
   "source": [
    "train(rnn_model, optimiser, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a3ef175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663\n"
     ]
    }
   ],
   "source": [
    "print(f'{accuracy(rnn_model, test_loader)[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed30693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def sample_text(model, loader):\n",
    "    articles = [a for a in loader]\n",
    "    data = random.choice(articles)\n",
    "    texts, _ = data[0].to(device), data[1].to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(texts)\n",
    "        predictions = torch.max(outputs, 1).indices\n",
    "    print(\"Input:\")\n",
    "    print(\" \".join([vocabulary.lookup_token(idx) for idx in texts[0]]))\n",
    "    print(f\"Prediction: {labels[predictions[0].item()]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534f0220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "apple #39 s flaming batteries recalled much loved music firm apple has had to recall more than 28 , 000 rechargeable batteries that it jacks into its aluminium 15-inch powerbook g4 because they may overheat . <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>\n",
      "Prediction: Sci/Tech\n"
     ]
    }
   ],
   "source": [
    "sample_text(rnn_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb38e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create confusion matrix\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d73f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327e204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc921f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed62b0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
